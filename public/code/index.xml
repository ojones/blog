<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Codes on Oswald Jones</title>
    <link>http://ojones.github.io/blog/code/</link>
    <description>Recent content in Codes on Oswald Jones</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Oswald Jones</copyright>
    <lastBuildDate>Fri, 21 Oct 2016 19:25:22 -0800</lastBuildDate>
    <atom:link href="http://ojones.github.io/blog/code/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Better HTML Table Parser</title>
      <link>http://ojones.github.io/blog/html_table_parser/</link>
      <pubDate>Fri, 21 Oct 2016 19:25:22 -0800</pubDate>
      
      <guid>http://ojones.github.io/blog/html_table_parser/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;$ pip install html_table_parser
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;synopsis:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;Synopsis&lt;/h2&gt;

&lt;p&gt;Transform html tables into usable data structures.  Using beautiful soup table object, return 2D array structure, dictionary, or array of column data.  Imputes cell values from row and col spans :)
&lt;a href=&#34;https://pure-river-60450.herokuapp.com/&#34; target=&#34;blank&#34;&gt;demo&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;code-example:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;Code Example&lt;/h2&gt;

&lt;p&gt;Given an html table (with or without row and col spans). You can make a 2D array&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bs4 import BeautifulSoup as bs
from html_table_parser import parser_functions as parse

soup = bs(YOUR_HTML_TABLE, &amp;quot;html.parser&amp;quot;)
test_table = soup.find(&#39;table&#39;)
twod_array = parse.make2d(test_table)

# print 2D array
print(twod_array)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use that 2D array to return column data by heading name&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print column data by col heading name (case insensitive)
print(parse.twod_col_data(twod_array, &#39;YOUR_COL_HEADING&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or transform the soup table object (test_table) into a dictionary&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# row data begins on first row after col headings
# so rowstart is 1
print(parse.make_dict(test_table, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;motivation:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;I looked everywhere for the code to transform html tables with row and col spans into a 2D array and couldn&amp;rsquo;t find it.  So I thought how hard could it be to quickly write my own.  It was actally kinda hard, so here it is for the next guy.&lt;/p&gt;

&lt;h2 id=&#34;installation:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Works on Python 2.7 and Python &amp;gt;3.4.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;$ pip install html_table_parser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;git clone https://github.com/ojones/html_table_parser.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tests:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;Tests&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;$ py.test
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;contributors:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;Contributors&lt;/h2&gt;

&lt;p&gt;Don&amp;rsquo;t be shy.&lt;/p&gt;

&lt;h2 id=&#34;license:2e8e527b21ef2deedced2078cd8e4e6a&#34;&gt;License&lt;/h2&gt;

&lt;p&gt;MIT&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cityholla</title>
      <link>http://ojones.github.io/blog/cityhollalanding/</link>
      <pubDate>Mon, 25 Jan 2016 19:25:22 -0800</pubDate>
      
      <guid>http://ojones.github.io/blog/cityhollalanding/</guid>
      <description>&lt;p&gt;The Cityholla project was a finalist for the city of Santa Monica &lt;a href=&#34;http://hackthebeach.com/contest/&#34;&gt;&amp;ldquo;Hack the Beach&amp;rdquo;&lt;/a&gt; contest 2015.  The code repo is private, but you can see our splash page &lt;a href=&#34;https://desolate-lake-19599.herokuapp.com/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;They say that Moore&amp;rsquo;s law only applies to hardware, but I agree with &lt;a href=&#34;http://www.kurzweilai.net/&#34;&gt;Ray Kurzweil&lt;/a&gt; that software is also advancing at a more than linear rate.&lt;/p&gt;

&lt;p&gt;I got a text on Sunday to create a landing page to display details and collect emails.  I had the site up and running on heroku that very night.  (Thanks &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;Just a couple years ago, this same splash page would have taken a team of front end engineers a full 2 week sprint.  The landing page code is public.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;git clone https://github.com/ojones/cityhollalanding.git
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Better Wikipedia Parser</title>
      <link>http://ojones.github.io/blog/wikipedia_parser/</link>
      <pubDate>Fri, 02 Oct 2015 19:25:22 -0800</pubDate>
      
      <guid>http://ojones.github.io/blog/wikipedia_parser/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;$ pip install wikipedia_parser
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;synopsis:907c88537397ec981ae3b6c17395c58b&#34;&gt;Synopsis&lt;/h2&gt;

&lt;p&gt;Uses Wikipedia API to store page id, title, html, wiki text, expanded templates, categories, page links, and summary in one class object for easy reference.  Also parses infobox data from wiki text, including page name, template name, image name, image url, and labeled key value data.&lt;/p&gt;

&lt;h2 id=&#34;code-example:907c88537397ec981ae3b6c17395c58b&#34;&gt;Code Example&lt;/h2&gt;

&lt;p&gt;Instantiate Wikipedia API object with page name or id:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from wikipedia_parser.wikipedia_api import WikipediaAPI
# wikipedia search id can be digit or name (redirects are handled :)
search_id = &#39;Ada_Lovelace&#39;
wiki_api = WikipediaAPI(search_id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is the print list of available api resources&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt; print(dir(wiki_api))
[   ...
    &#39;categories&#39;,
    &#39;expanded_html&#39;,
    &#39;html&#39;,
    &#39;page_id&#39;,
    &#39;page_links&#39;,
    &#39;search_id&#39;,
    &#39;summary&#39;,
    &#39;title&#39;,
    &#39;wiki_text&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If an infobox is present on page, you can parse the infobox data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from wikipedia_parser.infobox import Infobox
# wiki text can be from anywhere, does not need to come from WikipediaAPI object
wiki_text = wiki_api.wiki_text
infobox = Infobox(wiki_text)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is the print list of available attributes&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt; print(dir(infobox))
[   ...
    &#39;data&#39;,
    &#39;image_filename&#39;,
    &#39;image_url&#39;,
    &#39;page_name&#39;,
    &#39;template_name&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Infobox &amp;ldquo;data&amp;rdquo; is a dict with keys and values from wikipedia page&amp;rsquo;s infobox (if page has infobox).
&lt;br&gt;Each key field in data returns a dict with values for &amp;lsquo;plain_text&amp;rsquo;, &amp;lsquo;raw_text&amp;rsquo;, and &amp;lsquo;wiki_links&amp;rsquo;.
&lt;br&gt;Compare with &lt;a href=&#34;https://en.wikipedia.org/wiki/Ada_Lovelace&#34; target=&#34;_blank&#34;&gt;Ada_Lovelace&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# infobox.data for &amp;quot;Ada_Lovelace&amp;quot; returns:
{u&#39;birth_date&#39;: {
    &#39;plain_text&#39;: u&#39;&#39;,
    &#39;raw_text&#39;: u&#39;{{birth date|1815|12|10|df=yes}}&#39;,
    &#39;wiki_links&#39;: []},
u&#39;birth_name&#39;: {
    &#39;plain_text&#39;: u&#39;The Hon. Augusta Ada Byron&#39;,
    &#39;raw_text&#39;: u&#39;The Hon. Augusta Ada Byron&#39;,
    &#39;wiki_links&#39;: []},
u&#39;birth_place&#39;: {
    &#39;plain_text&#39;: u&#39;London, England&#39;,
    &#39;raw_text&#39;: u&#39;London, England&#39;,
    &#39;wiki_links&#39;: []},
u&#39;caption&#39;: {
    &#39;plain_text&#39;: u&#39;Ada, Countess of Lovelace, 1840&#39;,
    &#39;raw_text&#39;: u&#39;Ada, Countess of Lovelace, 1840&#39;,
    &#39;wiki_links&#39;: []},
u&#39;children&#39;: {
    &#39;plain_text&#39;: u&#39;&#39;,
    &#39;raw_text&#39;: u&#39;{{plainlist |\n* [[Byron King-Noel, Viscount Ockham|Byron King-Noel, Viscount Ockham and 12th Baron Wentworth]]\n* [[Anne Blunt, 15th Baroness Wentworth]]\n* [[Ralph King-Milbanke, 2nd Earl of Lovelace]]}}&#39;,
    &#39;wiki_links&#39;: [u&#39;Byron King-Noel, Viscount Ockham&#39;,
                   u&#39;Anne Blunt, 15th Baroness Wentworth&#39;,
                   u&#39;Ralph King-Milbanke, 2nd Earl of Lovelace&#39;]},
u&#39;death_date&#39;: {
    &#39;plain_text&#39;: u&#39;&#39;,
    &#39;raw_text&#39;: u&#39;{{death date and age|1852|11|27|1815|12|10|df=yes}}&#39;,
    &#39;wiki_links&#39;: []},
u&#39;death_place&#39;: {
    &#39;plain_text&#39;: u&#39;Marylebone, London, England&#39;,
    &#39;raw_text&#39;: u&#39;[[Marylebone]], London, England&#39;,
    &#39;wiki_links&#39;: [u&#39;Marylebone&#39;]},
u&#39;field&#39;: {
    &#39;plain_text&#39;: u&#39;Mathematics, computing&#39;,
    &#39;raw_text&#39;: u&#39;Mathematics, computing&#39;,
    &#39;wiki_links&#39;: []},
u&#39;image&#39;: {
    &#39;plain_text&#39;: u&#39;Ada Lovelace portrait.jpg&#39;,
    &#39;raw_text&#39;: u&#39;Ada Lovelace portrait.jpg&#39;,
    &#39;wiki_links&#39;: []},
u&#39;name&#39;: {
    &#39;plain_text&#39;: u&#39;Ada, Countess of Lovelace&#39;,
    &#39;raw_text&#39;: u&#39;Ada, Countess of Lovelace&#39;,
    &#39;wiki_links&#39;: []},
u&#39;parents&#39;: {
    &#39;plain_text&#39;: u&#39;&#39;,
    &#39;raw_text&#39;: u&#39;{{plainlist |\n* [[Lord Byron|George Gordon Byron, 6th Baron Byron]]\n* [[Anne Isabella Byron, Baroness Byron|Anne Isabella Milbanke, 11th Baroness Wentworth]]\n  }}&#39;,
    &#39;wiki_links&#39;: [u&#39;Lord Byron&#39;, u&#39;Anne Isabella Byron, Baroness Byron&#39;]},
u&#39;resting_place&#39;: {
    &#39;plain_text&#39;: u&#39;Church of St. Mary Magdalene, Hucknall, Nottingham, England&#39;,
    &#39;raw_text&#39;: u&#39;[[Church of St. Mary Magdalene, Hucknall]], Nottingham, England&#39;,
    &#39;wiki_links&#39;: [u&#39;Church of St. Mary Magdalene, Hucknall&#39;]},
u&#39;spouse&#39;: {
    &#39;plain_text&#39;: u&#39;William King-Noel, 1st Earl of Lovelace&#39;,
    &#39;raw_text&#39;: u&#39;[[William King-Noel, 1st Earl of Lovelace]]&#39;,
    &#39;wiki_links&#39;: [u&#39;William King-Noel, 1st Earl of Lovelace&#39;]},
u&#39;title&#39;: {
    &#39;plain_text&#39;: u&#39;Countess of Lovelace&#39;,
    &#39;raw_text&#39;: u&#39;Countess of Lovelace&#39;,
    &#39;wiki_links&#39;: []}}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;motivation:907c88537397ec981ae3b6c17395c58b&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/spencermountain/wtf_wikipedia&#34;&gt;wtf_wikipedia&lt;/a&gt; and &lt;a href=&#34;https://github.com/earwig/mwparserfromhell&#34;&gt;mwparserfromhell&lt;/a&gt; were the best wikipedia parsers I could find.  This one is better.&lt;/p&gt;

&lt;h2 id=&#34;installation:907c88537397ec981ae3b6c17395c58b&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Currently only works on Python 2.7 :(&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;$ pip install wikipedia_parser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;git clone https://github.com/ojones/wikipedia_parser.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tests:907c88537397ec981ae3b6c17395c58b&#34;&gt;Tests&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;$ py.test
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;contributors:907c88537397ec981ae3b6c17395c58b&#34;&gt;Contributors&lt;/h2&gt;

&lt;p&gt;Don&amp;rsquo;t be shy.  Needs a couple updats for Python 3. Could use more functions to parse wiki templates such as &amp;ldquo;{{plainlist}}&amp;rdquo;&lt;/p&gt;

&lt;h2 id=&#34;license:907c88537397ec981ae3b6c17395c58b&#34;&gt;License&lt;/h2&gt;

&lt;p&gt;MIT&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CordFlow</title>
      <link>http://ojones.github.io/blog/cordflow/</link>
      <pubDate>Thu, 21 May 2015 19:25:22 -0800</pubDate>
      
      <guid>http://ojones.github.io/blog/cordflow/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;git clone https://github.com/ojones/CordFlow.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;synopsis:1665c900a994357c0fd7bd49c23dfebe&#34;&gt;Synopsis&lt;/h2&gt;

&lt;p&gt;Nifty &lt;a href=&#34;http://ojones.github.io/CordFlow/&#34;&gt;proof of concept&lt;/a&gt; that demonstrates how to convert paper to JSON.  Also demonstrates how the json object can be used to automatically generate a web form and apply the answers back to paper.&lt;/p&gt;

&lt;h2 id=&#34;motivation:1665c900a994357c0fd7bd49c23dfebe&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;We made this for a contest as a proof of concept.  There are still so many government paper forms.  Even fillable pdfs don&amp;rsquo;t easily let you apply webform data.  This project proves you can use javascript to convert paper into web objects with just an image of the paper form.&lt;/p&gt;

&lt;h2 id=&#34;installation:1665c900a994357c0fd7bd49c23dfebe&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Just open the index.html file in your web browser.&lt;/p&gt;

&lt;h2 id=&#34;license:1665c900a994357c0fd7bd49c23dfebe&#34;&gt;License&lt;/h2&gt;

&lt;p&gt;MIT&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Twitter Sentiment</title>
      <link>http://ojones.github.io/blog/ga_data_science/</link>
      <pubDate>Thu, 12 Feb 2015 19:25:22 -0800</pubDate>
      
      <guid>http://ojones.github.io/blog/ga_data_science/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;git clone https://github.com/ojones/ga_data_science.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not another Twitter sentiment analyzer&amp;hellip;&lt;/p&gt;

&lt;p&gt;This was &lt;a href=&#34;https://gentle-bayou-19852.herokuapp.com/&#34;&gt;my project&lt;/a&gt; from General Assembly Data Science course taught by Nick Stucky from Whisper.&lt;/p&gt;

&lt;p&gt;Say what you will about coding bootcamps, &lt;a href=&#34;https://generalassemb.ly/education/data-science&#34;&gt;this&lt;/a&gt; class was amazing.  Nick gave us a solid overview of the data science field in general.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML Class Library</title>
      <link>http://ojones.github.io/blog/coursera_ml_library/</link>
      <pubDate>Thu, 09 Oct 2014 19:25:22 -0800</pubDate>
      
      <guid>http://ojones.github.io/blog/coursera_ml_library/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-git&#34;&gt;git clone https://github.com/ojones/coursera_ml_library.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Project for Coursera Machine Learning class with Stanford Professor Andrew Ng.&lt;/p&gt;

&lt;p&gt;Most everyone already knows but in case you don&amp;rsquo;t.  &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;This&lt;/a&gt; is the best intro to machine learning in the world.  &lt;a href=&#34;http://www.andrewng.org/&#34;&gt;Andrew Ng&lt;/a&gt;, co-founder our Coursera, compassionately surveys the field of machine learning algorithms.  It is he who sparked my passion for data science and many thousands more.  And did I mention the class is free.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>